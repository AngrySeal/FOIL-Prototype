{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c20cb5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘build’: File exists\n",
      "/home/aseal/Documents/invint/build\n",
      "-- Configuring done\n",
      "-- Generating done\n",
      "-- Build files have been written to: /home/aseal/Documents/invint/build\n",
      "[  3%] Built target dtnode\n",
      "[  5%] \u001b[34m\u001b[1mPerforming update step for 'antlr4_runtime'\u001b[0m\n",
      "Ignoring path runtime/Cpp/runtime/thirdparty/utfcpp/\n",
      "Current branch master is up to date.\n",
      "Already up to date!\n",
      "[  6%] \u001b[34m\u001b[1mPerforming configure step for 'antlr4_runtime'\u001b[0m\n",
      "loading initial cache file /home/aseal/Documents/invint/build/antlr4_runtime/tmp/antlr4_runtime-cache-.cmake\n",
      "CMake Warning at CMakeLists.txt:7 (message):\n",
      "  Build type not set, falling back to Release mode.\n",
      "\n",
      "   To specify build type use:\n",
      "   -DCMAKE_BUILD_TYPE=<mode> where <mode> is Debug or Release.\n",
      "\n",
      "\n",
      "-- Building without demo. To enable demo build use: -DWITH_DEMO=True\n",
      "CMake Deprecation Warning at CMakeLists.txt:31 (CMAKE_POLICY):\n",
      "  The OLD behavior for policy CMP0054 will be removed from a future version\n",
      "  of CMake.\n",
      "\n",
      "  The cmake-policies(7) manual explains that the OLD behaviors of all\n",
      "  policies are deprecated and that a policy should be set to OLD only under\n",
      "  specific short-term circumstances.  Projects should be ported to the NEW\n",
      "  behavior and not rely on setting a policy to OLD.\n",
      "\n",
      "\n",
      "CMake Deprecation Warning at CMakeLists.txt:32 (CMAKE_POLICY):\n",
      "  The OLD behavior for policy CMP0045 will be removed from a future version\n",
      "  of CMake.\n",
      "\n",
      "  The cmake-policies(7) manual explains that the OLD behaviors of all\n",
      "  policies are deprecated and that a policy should be set to OLD only under\n",
      "  specific short-term circumstances.  Projects should be ported to the NEW\n",
      "  behavior and not rely on setting a policy to OLD.\n",
      "\n",
      "\n",
      "CMake Deprecation Warning at CMakeLists.txt:33 (CMAKE_POLICY):\n",
      "  The OLD behavior for policy CMP0042 will be removed from a future version\n",
      "  of CMake.\n",
      "\n",
      "  The cmake-policies(7) manual explains that the OLD behaviors of all\n",
      "  policies are deprecated and that a policy should be set to OLD only under\n",
      "  specific short-term circumstances.  Projects should be ported to the NEW\n",
      "  behavior and not rely on setting a policy to OLD.\n",
      "\n",
      "\n",
      "CMake Deprecation Warning at CMakeLists.txt:38 (CMAKE_POLICY):\n",
      "  The OLD behavior for policy CMP0059 will be removed from a future version\n",
      "  of CMake.\n",
      "\n",
      "  The cmake-policies(7) manual explains that the OLD behaviors of all\n",
      "  policies are deprecated and that a policy should be set to OLD only under\n",
      "  specific short-term circumstances.  Projects should be ported to the NEW\n",
      "  behavior and not rely on setting a policy to OLD.\n",
      "\n",
      "\n",
      "CMake Deprecation Warning at CMakeLists.txt:39 (CMAKE_POLICY):\n",
      "  The OLD behavior for policy CMP0054 will be removed from a future version\n",
      "  of CMake.\n",
      "\n",
      "  The cmake-policies(7) manual explains that the OLD behaviors of all\n",
      "  policies are deprecated and that a policy should be set to OLD only under\n",
      "  specific short-term circumstances.  Projects should be ported to the NEW\n",
      "  behavior and not rely on setting a policy to OLD.\n",
      "\n",
      "\n",
      "-- Output libraries to /home/aseal/Documents/invint/build/antlr4_runtime/src/antlr4_runtime/runtime/Cpp/dist\n",
      "-- Configuring done\n",
      "-- Generating done\n",
      "-- Build files have been written to: /home/aseal/Documents/invint/build/antlr4_runtime/src/antlr4_runtime/runtime/Cpp\n",
      "[  8%] \u001b[34m\u001b[1mNo build step for 'antlr4_runtime'\u001b[0m\n",
      "[ 10%] \u001b[34m\u001b[1mNo install step for 'antlr4_runtime'\u001b[0m\n",
      "[ 11%] \u001b[34m\u001b[1mCompleted 'antlr4_runtime'\u001b[0m\n",
      "[ 16%] Built target antlr4_runtime\n",
      "[ 18%] Built target antlr4_runtime-build_static\n",
      "[ 28%] Built target qChecker\n",
      "[ 32%] Built target fpow\n",
      "[ 42%] Built target gVisitor\n",
      "[ 45%] Built target errorListener\n",
      "[ 49%] Built target dt\n",
      "[ 52%] Built target perceptron\n",
      "[ 54%] \u001b[32m\u001b[1mLinking CXX executable main\u001b[0m\n",
      "[ 62%] Built target main\n",
      "[ 72%] Built target paperalgo\n",
      "[ 83%] Built target qChecker2\n",
      "[ 84%] \u001b[32m\u001b[1mLinking CXX executable main2\u001b[0m\n",
      "[ 93%] Built target main2\n",
      "[ 96%] Built target dttest\n",
      "[100%] Built target test_generator\n"
     ]
    }
   ],
   "source": [
    "!mkdir build\n",
    "%cd build\n",
    "!cmake ../\n",
    "!make"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e72bf241",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import subprocess\n",
    "import numpy as np\n",
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb88d7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def time1(query):\n",
    "    q = open(\"query.txt\",\"w\")\n",
    "    q.write(query + \"\\n\")\n",
    "    q.close()\n",
    "    times = []\n",
    "    out = \"\"\n",
    "    for i in range(5):\n",
    "        d1 = time.process_time()\n",
    "        try:\n",
    "            sp = subprocess.run(\"./main2 --model=dt --file=dt.txt < query.txt\", shell = True, capture_output = True, timeout = 60)\n",
    "            out = sp.stdout.splitlines()[2]\n",
    "        except:\n",
    "            print(\"timeout with query \" + query)\n",
    "            times = [10,10,10,10,10]\n",
    "            out = \"timeout\"\n",
    "            break\n",
    "        #timeout!!!\n",
    "        d2 = time.process_time()\n",
    "        times.append(d2-d1)\n",
    "    return (times , out)\n",
    "\n",
    "def random_constant(query , dt_size):\n",
    "    ans = \"\"\n",
    "    idx = 1\n",
    "    for i in range(len(query[0])):\n",
    "        if (query[0][i] == 'C'):\n",
    "            ans+=\"[ \"\n",
    "            for j in range(dt_size):\n",
    "                if (j):\n",
    "                    ans += \" , \"\n",
    "                val = query[idx][j]\n",
    "                if (val == 2): val = '?'\n",
    "                else: val = str(val)\n",
    "                ans += val\n",
    "            ans += \" ] \"\n",
    "            idx+=1\n",
    "        else:\n",
    "            ans+=query[0][i]\n",
    "    return ans\n",
    "\n",
    "def generate_query(squeries , nvars , rng):\n",
    "    query = \"\"\n",
    "    isnot = rng.integers(2)\n",
    "    if (isnot):\n",
    "        query += \" ~ ( \"\n",
    "    if (squeries == 1):\n",
    "        \n",
    "        if (nvars == 1):\n",
    "            opt = rng.integers(3)\n",
    "        else:\n",
    "            opt = rng.integers(4)\n",
    "        \n",
    "        if (opt == 0):\n",
    "            \n",
    "            query += \" P ( x\" + str( rng.integers(nvars) + 1 ) + \" ) \"\n",
    "        \n",
    "        if (opt == 1):\n",
    "            \n",
    "            query += \" C <= x\" + str( rng.integers(nvars) + 1 ) + \" \"\n",
    "        \n",
    "        if (opt == 2):\n",
    "            \n",
    "            query += \" x\" + str( rng.integers(nvars) + 1 ) + \" <= C \"\n",
    "            \n",
    "        if (opt == 3):\n",
    "            \n",
    "            x1 = rng.integers(nvars) + 1\n",
    "            x2 = rng.integers(nvars) + 1\n",
    "            while (x2 == x1):\n",
    "                x2 = rng.integers(nvars) + 1\n",
    "            query += \" x\" + str(x1) + \" <= x\" + str(x2) + \" \"\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        query += \" ( \"\n",
    "        fs = rng.integers(squeries-1) + 1\n",
    "        query += generate_query(fs , nvars , rng)\n",
    "        \n",
    "        if ( rng.integers(2) ):\n",
    "            query += \" ) V ( \"\n",
    "        else:\n",
    "            query += \" ) ^ ( \"\n",
    "            \n",
    "        query += generate_query(squeries - fs , nvars , rng) + \" ) \"\n",
    "    \n",
    "    if (isnot):\n",
    "        query += \" ) \"\n",
    "    \n",
    "    return query\n",
    "\n",
    "def time_queries(dt_name , queries, rng):\n",
    "    \n",
    "    data = {}\n",
    "    \n",
    "    with open(\"../dtrees/\" + dt_name) as json_file:\n",
    "        data = json.load(json_file)\n",
    "        \n",
    "    with open('dt.txt', 'w') as outfile:\n",
    "        json.dump(data, outfile)\n",
    "    \n",
    "    times = []\n",
    "    timesr = []\n",
    "    \n",
    "    for q in queries:\n",
    "        queryt = random_constant(q , len( data[\"feature_names\"] ) )\n",
    "        ctimes = time1( queryt )\n",
    "        timep = ( sum(ctimes[0]) - max(ctimes[0]) - min(ctimes[0]))/3\n",
    "        timesr.append( timep )\n",
    "        finalarr = [queryt] + ctimes[0] + [ctimes[1]] + [timep]\n",
    "        times.append(finalarr)\n",
    "        \n",
    "    df = pd.DataFrame( times , columns = [\"query\" , \"t1\" , \"t2\" , \"t3\" , \"t4\" , \"t5\" , \"ans\" , \"tp\"] )\n",
    "    \n",
    "    df.to_csv(dt_name + \".csv\")\n",
    "    \n",
    "    return timesr\n",
    "\n",
    "def test_trees(qsize, nvars , nqueries, seed):\n",
    "    data = []\n",
    "    rng = np.random.default_rng(seed)\n",
    "    queries = []\n",
    "    dims = [3, 5, 10, 15, 20, 25, 30]\n",
    "    leaves =  [5, 10, 15, 20, 50, 100, 150, 200, 500, 1000, 2000]\n",
    "    for i in range(nqueries):\n",
    "        q = \"\"\n",
    "        ex = rng.integers(2)\n",
    "        for j in range(nvars):\n",
    "            if (ex):\n",
    "                q += \"Exists x\" + str(j + 1) + \", \"\n",
    "            else:\n",
    "                q += \"Forall x\" + str(j + 1) + \", \"\n",
    "        q += generate_query(qsize , nvars , rng)\n",
    "        nconstants = q.count('C')\n",
    "        fquery = [q]\n",
    "        for i in range(nconstants):\n",
    "            c = []\n",
    "            for j in range( max(dims) ):\n",
    "                c.append( rng.integers(3) )\n",
    "            fquery.append(c)\n",
    "        queries.append(fquery)\n",
    "    infop = [ ]\n",
    "    for l in leaves:\n",
    "        for d in dims:\n",
    "            infop.append( [d , l ] +  time_queries( \"dim_\" + str(d) + \"_nleaves_\" + str(l) + \".json\" , queries , rng) )\n",
    "            print( str(l) + \" \" + str(d) + \" \" + str(sum(infop[len(infop)-1][2:])/nqueries) )\n",
    "    \n",
    "    qs = []\n",
    "    for i in range(nqueries):\n",
    "        qs.append( queries[i][0] )\n",
    "    df = pd.DataFrame( infop , columns = [\"dimension\" , \"leaves\" ] + qs )\n",
    "    df.to_csv(\"final_data.csv\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82066eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_trees(8,3,10,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cabc72ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_constant(max_s,rng):\n",
    "    return rng.integers(3,size=max_s)\n",
    "\n",
    "def replace_constants(q , cs, dim):\n",
    "    nq = \"\"\n",
    "    idx = 0\n",
    "    for l in q:\n",
    "        if l == 'C':\n",
    "            nq += \" [ \"\n",
    "            for j in range(dim):\n",
    "                if (j): nq += \" , \"\n",
    "                if (cs[idx][j] == 2): nq += \" ? \"\n",
    "                else: nq += str(cs[idx][j])\n",
    "            nq += \" ] \"\n",
    "            idx+=1\n",
    "        else: nq += l\n",
    "    return nq\n",
    "\n",
    "def load_tree(dt_name):\n",
    "    with open(\"../dtrees/\" + dt_name) as json_file:\n",
    "        data = json.load(json_file)\n",
    "        \n",
    "    with open('dt.txt', 'w') as outfile:\n",
    "        json.dump(data, outfile)\n",
    "        \n",
    "def queries_with_tree( dim, leaves, queries, constants ):\n",
    "    load_tree(\"dim_\" + str(dim) + \"_nleaves_\" + str(leaves) + \".json\")\n",
    "    n = len(queries)\n",
    "    info = [ dim , leaves ]\n",
    "    table = []\n",
    "    \n",
    "    for i in range(n):\n",
    "        q = replace_constants(queries[i] , constants[i] , dim)\n",
    "        tims =  time1( q )\n",
    "        tp = (sum( tims[0] ) - max(tims[0]) - min(tims[0]) )/3\n",
    "        info.append(tp)\n",
    "        table.append( [ q ] + tims[0] + [ tims[1] , tp ]  )\n",
    "    \n",
    "    df = pd.DataFrame( table , columns = [\"query\" , \"t1\" , \"t2\" , \"t3\" , \"t4\" , \"t5\" , \"ans\" , \"tp\"] )\n",
    "    \n",
    "    df.to_csv( \"dim_\" + str(dim) + \"_nleaves_\" + str(leaves) + \".csv\")\n",
    "    \n",
    "    return info\n",
    "    \n",
    "\n",
    "def run_queries(queries , seed):\n",
    "    \n",
    "    dims = [3, 5, 10, 15, 20, 25, 30]\n",
    "    leaves =  [5, 10, 15, 20, 50, 100, 150, 200, 500, 1000, 2000]\n",
    "    \n",
    "    cs = []\n",
    "    rng = np.random.default_rng()\n",
    "    for query in queries:\n",
    "        cc = []\n",
    "        for j in range( query.count('C') ):\n",
    "            cc.append( create_constant( max(dims) , rng ) )\n",
    "        cs.append(cc)\n",
    "    \n",
    "    table = []\n",
    "    \n",
    "    \n",
    "    for dim in dims:\n",
    "        for leaf in leaves:\n",
    "            table.append( queries_with_tree(dim , leaf , queries , cs) )\n",
    "            \n",
    "    df = pd.DataFrame( table , columns = [\"dimension\" , \"leaves\" ] + queries )\n",
    "    df.to_csv(\"queries.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bc99cd9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_queries([\"Exists x, P(x)\" , \"Exists x, ~ ( P(x) )\" , \"Exists x, Exists y, ( P(x) ) ^ ( ~ ( P ( y ) ) )\" , \"ForAll x, ForAll y, (( P(x) ) V ( P(y) )) V  ( (x <= C) ^ (y <= C))\"] , 10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
